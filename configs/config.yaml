# GPU-Optimized Configuration for GTX 1650 (4GB VRAM)
project_name: "exercise_recognition"
experiment_name: "mediapipe_vit_gpu"

data:
  raw_path: "data/raw"
  processed_path: "data/processed"
  splits_path: "data/processed/splits"
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15
  seed: 42

pose:
  model_complexity: 1
  min_detection_confidence: 0.5
  min_tracking_confidence: 0.5
  static_image_mode: false
  num_keypoints: 33
  temporal_window: 20  # Shorter sequences = less memory

model:
  type: "vit"  # Changed from "post_vit" to "vit"

  vit:
    embed_dim: 128  # Smaller model for 4GB VRAM
    depth: 4  # 4 layers instead of 6
    num_heads: 4  # 4 heads instead of 8
    mlp_ratio: 4
    dropout: 0.1
    max_seq_len: 100

  lstm:
    hidden_dim: 128
    num_layers: 2
    dropout: 0.3
    bidirectional: true

training:
  epochs: 30
  batch_size: 48  # Tuned for 4GB VRAM
  learning_rate: 0.0003
  weight_decay: 0.0001
  optimizer: "adamw"
  scheduler: "cosine"
  warmup_epochs: 3

  augmentation:
    temporal_jitter: true
    spatial_noise: 0.02
    random_temporal_crop: true

  patience: 7
  min_delta: 0.001

inference:
  fps_target: 30
  confidence_threshold: 0.6
  smoothing_window: 5

paths:
  checkpoints: "models/checkpoints"
  final_model: "models/final"
  onnx_model: "models/onnx"
  logs: "logs"
  tensorboard: "runs"
